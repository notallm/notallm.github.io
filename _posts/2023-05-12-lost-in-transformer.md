---
layout: post
title: "Lost in a Transformer: The Blur Between Human and AI Content"
---

The latest breakthroughs in large language models have fundamentally challenged our understanding of the nature of comprehension. The implications of these advancements are multifaceted, and many questions arise regarding what the future holds and how we can rise to meet the challenge. The gravity of this issue rests heavily on the shoulders of educators, who must rebuild the system from the ground up to train a new generation of students, one that is not merely capable of engineering original prompts but novel concepts and ideas.

---

After the release of The Terminator, the most prominent question related to advancements in artificial intelligence (AI) was whether our future would be met with a Skynet-esque doom. Although we are not there yet, every announcement of a new large language model seems to bring us one step closer. Unless you live under a rock, you will have noticed the burst of these models falling into mainstream media. Nearly every company, organization, news outlet, or even individual is making or integrating these models into their workflows. With every interaction with the models, the notions generated and the flow of words make it so apparent — models have surpassed what we thought they were capable of, exhibiting human-level proficiency in all tasks. As a student, I have witnessed firsthand how models like OpenAI’s ChatGPT have crushed every mundane assignment and essay assigned. Simply put, thinking cannot match the sheer efficiency of inputting a prompt into ChatGPT and having it generate thought-provoking and intelligent text.

The latest addition to the family of large language models is OpenAI’s multimodal model, GPT-4, which can accept text and images and respond to complex queries with proper answers. Released on March 14, only four months after the initial release of ChatGPT, the model has outperformed its predecessor, GPT-3.5, the model powering the chatbot, in nearly every exam, with near-human accuracy. It can ace almost every machine learning benchmark, including the A12 Reasoning Challenge and HellaSwag. What can your four-month-old human baby do? I bet they can not get a four or five on almost all of the toughest Advanced Placement (AP) exams. Organizations have picked up on this, with Duolingo and Khan Academy partnering with OpenAI to integrate the model into their programs, giving value and increasing the prevalence of AI.

The rise of AI-generated content has brought an increasing blur between human and AI content, raising ethical and moral concerns. It has simply transformed the way content is produced and consumed. As AI-generated content continues to improve and surpass human-level proficiency at an astonishing rate, it raises fundamental questions about the future of human creativity and reasoning. If AI can produce answers that can surpass humans and improve on itself in a span of 4 months, what does the future hold? How is anyone on the internet supposed to differentiate what is human and what is AI? Creativity and reasoning used to be the argument against AI taking over our jobs and world, but we no longer have that; are humans obsolete? The answers to these questions are technical and philosophical, and they will no doubt define the rest of human history. From here on out, each word will follow a question: who’s there, a transformer or a human?

---

Technology is an ever-evolving field, inspiring a hustle culture that rewards speed and innovation. In this realm, time to market defines the pace of progress. OpenAI, with its ChatGPT model, has mastered both aspects with poise. Every major technology organization had created its version of a powerful large language model under wraps from the public, but OpenAI was the first to commercialize it. Being a startup, they benefited from not having the same cumbersome layers of checks and balances that established companies have, meaning they can quickly ship new features. It’s akin to the philosophy of Facebook (now Meta) when it first began: move fast and break things. OpenAI has a team of excellent programmers and engineers who have not dramatically broken their system. Instead, they have broken the fabric of what it means to understand.

What makes this shocking is that the ChatGPT model does not even truly understand what it’s outputting. Language can not explain language, but, as research shows, tensors can. The underlying technology that powers every functional large language model is the transformer, represented by the “T” in GPT. The transformer layer calculates attention weights for input tensors, which allows it to learn the nuances of language and encapsulate them into numbers. Data ripples through these tens of times, with hidden tensors in the thousands and parameters in the billions, in an attempt to understand text. The deep and thought-provoking essay you turned in by giving ChatGPT your prompt? It was a series of tensors decoded into something we can understand and relate to. By providing it with vast amounts of data scraped from across the web, the model has learned to “understand” and interpret sarcasm, humor, debate, facts, and even emotion. The fundamental question may not be human or AI, but rather what is “understanding.”

Comprehension of text involves both existing knowledge and the generation of new insights, which necessitates the interaction of numerous neurological systems. While mainstream large language models have yet to attain this level of understanding, it is an inevitable outcome. Thus, the question of whether humans and creativity have become obsolete remains to be answered. The future is uncertain, and it is difficult to predict what developments lie ahead. A groundbreaking paper akin to the introduction of the transformer could emerge, or researchers might incorporate neuroscience to develop biologically plausible neural networks. What is certain, however, is that the culture of industriousness will continue to inspire advancements in language models. It may be soon that GPT-4 evolves into GPT-10, and language models approach a level of perceived sentience. The logical line of thought from this is simple; humans need to out-human a computer.

The challenge ahead is hardly a trivial one. By their very nature, schools are designed to cultivate a train of thought that values memorization and penalizes deviation from established norms. The result is a system that rewards the ability to churn out cookie-cutter responses over originality and creativity. No need exists for uninspired “busy work” that any run-of-the-mill model can efficiently complete, as if there ever was. Educational institutions have recently begun to take notice of the increasing prevalence of AI-generated content in student submissions, but their response has been tepid at best. Enforcing tools like GPTZero or Turnitin’s AI checker is futile — the tools used to generate content are evolving at an astonishing rate. In the face of mainstream models, traditional essay prompts and assignments are left in the dust. In order to stay ahead of the curve, educators must be willing to adapt to this rapidly changing landscape, lest they be left behind in a world where all assignments are AI-generated. It is crucial to keep the integrity of education and for teachers to begin teaching past what has already been discovered — breed thinkers of new ideas, not new prompts.

---

In a world where the Turing Test became obsolete years prior, differentiating between humans and AI has become a near-impossible task. From the eyes of educators, the only solution to keep the system sound is a rebuild from the ground up. For those students and even those writing content, AI does not have to be your second brain. The entirety of the text above embellishes AI as the disruptor of what it means to think, and it is. If there is one notion any reader takes away, it should be this: why create original content? Because that is what humans are meant to do. The question from here forth will be who’s there, but it is up to you to say, me, a human.
